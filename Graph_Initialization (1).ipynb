{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWGkd0ZOqb-X"
      },
      "source": [
        "##### Installs (only run once):\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDnxNGBNqOr5"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle --upgrade # for kaggle download\n",
        "!pip install -U sentence-transformers # for SBERT pre-trained download\n",
        "!pip install torch-geometric\n",
        "!pip install pyg-lib torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-1.13.1+cu116.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjBZKzkzqm8M"
      },
      "source": [
        "##### Imports:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6L_t_4ilqiAp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from random import sample\n",
        "import pickle\n",
        "from IPython.display import HTML, display\n",
        "from google.colab import drive\n",
        "import torch\n",
        "from sentence_transformers import util\n",
        "import gensim.downloader # pretrained word2vec and glove: https://radimrehurek.com/gensim/models/word2vec.html, https://github.com/RaRe-Technologies/gensim-data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEoPSBnRquZe"
      },
      "source": [
        "##### Load and process a common nouns dataset from Kaggle:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIDa1fZrqyBn"
      },
      "outputs": [],
      "source": [
        "# downloading kaggle noun dataset - only need to run once\n",
        "os.environ['KAGGLE_USERNAME'] = ''\n",
        "os.environ['KAGGLE_KEY'] = ''\n",
        "!kaggle datasets download -d leite0407/list-of-nouns # https://www.kaggle.com/datasets/leite0407/list-of-nouns\n",
        "!unzip list-of-nouns.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgUn6lBxrPOl"
      },
      "outputs": [],
      "source": [
        "# cleaning the data\n",
        "nouns = pd.read_csv('nounlist.csv').values.tolist()\n",
        "for i in range(len(nouns)):\n",
        "  nouns[i]=nouns[i][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vccjCOJirOMU"
      },
      "source": [
        "##### Setting up our Node class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4tLgNFDrcNL"
      },
      "outputs": [],
      "source": [
        "class Node():\n",
        "  def __init__(self, embedding, engl, edges, edgeweights, idx):\n",
        "    self.emb = embedding # onehot or pre-embed encoding\n",
        "    self.en = engl # english word\n",
        "    self.edges = edges # list of connected edges\n",
        "    self.edgew = edgeweights # edgeweights corresponding to edges\n",
        "    self.idx = idx # node index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rak0Xptorgqj"
      },
      "source": [
        "##### Building a graph:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0v7z2FEnrral"
      },
      "source": [
        "Loading a pretrained model to select edges (could also use a comatrix):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1vQxoMDrjlH"
      },
      "outputs": [],
      "source": [
        "word2vec = gensim.downloader.load(\"word2vec-google-news-300\") # load a pretrained word2vec model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M9wEYO-r9nb"
      },
      "source": [
        "##### Test the pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btnQmyGnr8Pf"
      },
      "outputs": [],
      "source": [
        "word = nouns[random.randint(0, len(nouns)-1)] # choose a random word from our words dataset\n",
        "print(\"Model: word2vec\")\n",
        "print(\"Word: \" + word)\n",
        "print(\"Embedding shape: \" + str(word2vec[word].shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beBJNXv7ryPc"
      },
      "source": [
        "##### Define a onehot encoding function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGd82Czur1PY"
      },
      "outputs": [],
      "source": [
        "def onehot(word):\n",
        "  v = torch.zeros(len(nouns))\n",
        "  v[nouns.index(word)] = 1\n",
        "  return v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQCg3ljer0nf"
      },
      "source": [
        "##### Create a graph of noun nodes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gyXg8k7sZb-"
      },
      "outputs": [],
      "source": [
        "strToNode = {} # dictionary that maps the english words to their nodes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWbrB6Bcs3O5"
      },
      "source": [
        "##### Quick function to visualizing model progress:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJWSZidjs18A"
      },
      "outputs": [],
      "source": [
        "# src: https://stackoverflow.com/questions/46939393/how-do-i-use-updatable-displays-on-colab\n",
        "def progressbar(value, max=100):\n",
        "    return HTML(\"\"\"\n",
        "        <progress\n",
        "            value='{value}'\n",
        "            max='{max}',\n",
        "            style='width: 80%'\n",
        "        >\n",
        "            {value}\n",
        "        </progress>\n",
        "    \"\"\".format(value=value, max=max))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIeRSLlStXw4"
      },
      "source": [
        "##### Initialize each node and add it to the dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nWSUC8VwtKj0"
      },
      "outputs": [],
      "source": [
        "progress = display(progressbar(0, len(nouns)), display_id=True)\n",
        "for w in range(len(nouns)):\n",
        "  cword = nouns[w] # current word\n",
        "  sim_words = [] # edges\n",
        "  sim_vals = [] # edge weights\n",
        "\n",
        "  outofvocab=0 # ignore words not in the word2vec vocab\n",
        "  for i in range(len(nouns)):\n",
        "    pword = nouns[i] # potential edge\n",
        "    if(pword!=cword): # make sure they aren't the same word\n",
        "      try:\n",
        "        sim = word2vec.similarity(cword, pword)\n",
        "        if(sim > .45): # iterate through every other word, if its similarity is above the threshold then add it as an edge with the similarity as the weight\n",
        "          sim_words.append(pword)\n",
        "          sim_vals.append(sim)\n",
        "      except:\n",
        "        outofvocab+=1\n",
        "    \n",
        "  # create the node and add it to our graph\n",
        "  if(outofvocab < 300): # check to make sure cword is in vocab\n",
        "    wordnode = Node(word2vec[cword], cword, sim_words, sim_vals, w)\n",
        "    strToNode.update({cword: wordnode})\n",
        "\n",
        "  # update our progress bar\n",
        "  if(w%50 == 0):\n",
        "    progress.update(progressbar(w, len(nouns)))\n",
        "progress.update(progressbar(len(nouns), len(nouns)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xBCQS15wrO6"
      },
      "source": [
        "Testing the graph:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFdLEvsQwOHd"
      },
      "outputs": [],
      "source": [
        "word = 'apple'\n",
        "print(\"Word: \"+word)\n",
        "print(\"Embedding Shape: \" + str(strToNode[word].emb.shape))\n",
        "print(\"Edges: \" + strToNode[word].edges)\n",
        "print(\"Edgeweights: \" + strToNode[word].edgew)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpk3Tn0luFh0"
      },
      "source": [
        "##### Save our graph to google drive:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jERykOoyuFNB"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YodZSuRDvBOb"
      },
      "outputs": [],
      "source": [
        "def Save(graph):\n",
        "    writename = \"init-graph-w2vec-.35thresh\"\n",
        "    with open(\"/content/drive/My Drive/J-Term 2023/input-graphs/\"+writename+\".txt\", \"wb\") as pkl_handle:\n",
        "        pickle.dump(graph, pkl_handle)\n",
        "Save(strToNode)\n",
        "del(strToNode)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwR78oD4vNNl"
      },
      "source": [
        "##### Print all saved graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xf6YMpnlvMu2"
      },
      "outputs": [],
      "source": [
        "saved = os.listdir(\"/content/drive/My Drive/J-Term 2023/input-graphs\")\n",
        "t=[print(str(i)+\": \"+saved[i]) for i in range(len(saved))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpRwKxDhNYHe"
      },
      "outputs": [],
      "source": [
        "def Load(graphname):\n",
        "    with open(\"/content/drive/My Drive/J-Term 2023/input-graphs/\" + graphname, \"rb\") as pkl_handle:\n",
        "        output = pickle.load(pkl_handle)\n",
        "        print(\"loaded: \"+graphname)\n",
        "        return output\n",
        "\n",
        "loaded_graph = Load(saved[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbOkmhrYKv4W"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plotted = {} # idx: (xcor, ycor)\n",
        "for i in range(0, 10):\n",
        "  x = random.randint(0,20)\n",
        "  y = random.randint(0,20)\n",
        "  plotted.update({i: [x,y]})\n",
        "  plt.plot(x,y, marker=\"bo\")\n",
        "  for e in strToNode[strToNode[i]].edges:\n",
        "    if(e.idx < i):\n",
        "      plt.plot([x, plotted[e.idx][0]], [y, plotted[e.idx][1]])\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}